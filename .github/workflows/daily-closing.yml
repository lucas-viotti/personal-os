# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Daily Closing

# AI-powered end-of-day summary with activity analysis
# Requires secrets: ATLASSIAN_*, LLM_*, SLACK_*

on:
  schedule:
    # 5:50 PM BRT (20:50 UTC) Mon-Fri
    - cron: '50 20 * * 1-5'
  workflow_dispatch:

env:
  LLM_MODEL: "gpt-4o-mini"

jobs:
  daily-closing:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # ============================================
      # STEP 1: GATHER TODAY'S ACTIVITY
      # ============================================
      
      - name: Fetch Jira Activity
        id: jira
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          JIRA_PROJECT: ${{ secrets.JIRA_PROJECT }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$JIRA_PROJECT" ]; then
            echo "jira_data=_Jira not configured_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching today's Jira activity from $ATLASSIAN_DOMAIN..."
          
          # Use new Jira API endpoint (POST /rest/api/3/search/jql)
          # Filter to issues where user is assignee, reporter, or watcher (mentioned)
          JQL="project = ${JIRA_PROJECT} AND (assignee = \"${ATLASSIAN_EMAIL}\" OR reporter = \"${ATLASSIAN_EMAIL}\" OR watcher = \"${ATLASSIAN_EMAIL}\") AND updated >= startOfDay() ORDER BY updated DESC"
          
          echo "JQL: $JQL"
          
          # Create JSON payload for POST request
          JSON_PAYLOAD=$(jq -n \
            --arg jql "$JQL" \
            '{
              "jql": $jql,
              "maxResults": 30,
              "fields": ["key", "summary", "status", "assignee", "updated"]
            }')
          
          JIRA_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
            -X POST \
            -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://${ATLASSIAN_DOMAIN}/rest/api/3/search/jql" \
            -d "$JSON_PAYLOAD")
          
          # Extract HTTP code and response body
          HTTP_CODE=$(echo "$JIRA_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
          RESPONSE_BODY=$(echo "$JIRA_RESPONSE" | grep -v "HTTP_CODE:")
          
          echo "HTTP Code: $HTTP_CODE"
          echo "Response: ${RESPONSE_BODY:0:500}"
          
          if [ "$HTTP_CODE" != "200" ]; then
            echo "Jira API error: HTTP $HTTP_CODE"
            echo "jira_data=_Jira API error_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          JIRA_COUNT=$(echo "$RESPONSE_BODY" | jq -r '.issues | length' 2>/dev/null || echo "0")
          
          # Get full issue list for AI to summarize
          JIRA_RAW=$(echo "$RESPONSE_BODY" | jq -r '.issues[]? | "\(.key): \(.fields.summary) [\(.fields.status.name)]"' 2>/dev/null || echo "")
          
          echo "Found $JIRA_COUNT issues"
          
          if [ -z "$JIRA_RAW" ] || [ "$JIRA_COUNT" = "0" ]; then
            JIRA_RAW="_No Jira activity today_"
          fi
          
          echo "jira_raw<<EOF" >> $GITHUB_OUTPUT
          echo "$JIRA_RAW" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "jira_count=$JIRA_COUNT" >> $GITHUB_OUTPUT

      - name: Fetch Confluence Activity
        id: confluence
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          CONFLUENCE_SPACES: ${{ secrets.CONFLUENCE_SPACES }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$CONFLUENCE_SPACES" ]; then
            echo "confluence_data=_Confluence not configured_" >> $GITHUB_OUTPUT
            echo "confluence_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching today's Confluence activity..."
          
          ALL_PAGES=""
          TOTAL_COUNT=0
          TODAY_START=$(date -u +%Y-%m-%dT00:00:00)
          
          for SPACE in $(echo $CONFLUENCE_SPACES | tr ',' ' '); do
            RESPONSE=$(curl -s -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
              "https://${ATLASSIAN_DOMAIN}/wiki/rest/api/content?spaceKey=${SPACE}&expand=history.lastUpdated&limit=20&orderby=history.lastUpdated%20desc" \
              2>/dev/null || echo '{"results":[]}')
            
            PAGES=$(echo "$RESPONSE" | jq -r --arg today "$TODAY_START" \
              '.results[]? | select(.history.lastUpdated.when > $today) | "â€¢ \(.title)"' 2>/dev/null || echo "")
            
            if [ -n "$PAGES" ]; then
              ALL_PAGES="${ALL_PAGES}${PAGES}\n"
              COUNT=$(echo "$PAGES" | grep -c "â€¢" || echo "0")
              TOTAL_COUNT=$((TOTAL_COUNT + COUNT))
            fi
          done
          
          if [ -z "$ALL_PAGES" ] || [ "$TOTAL_COUNT" = "0" ]; then
            ALL_PAGES="_No Confluence edits today_"
          fi
          
          echo "confluence_data<<EOF" >> $GITHUB_OUTPUT
          echo -e "$ALL_PAGES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "confluence_count=$TOTAL_COUNT" >> $GITHUB_OUTPUT

      # Note: Slack message fetching requires user token (restricted in many companies)
      # For full Slack access, use the local script: scripts/logbook-local.py

      - name: Read Current Tasks
        id: tasks
        run: |
          # Get all active tasks with details
          TASK_DETAILS=""
          for file in Tasks/*.md; do
            [ -f "$file" ] || continue
            
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            PRIORITY=$(grep "^priority:" "$file" | sed 's/priority: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            
            case $STATUS in
              n) STATUS_TEXT="Not Started"; STATUS_EMOJI="ðŸ”´" ;;
              s|ip) STATUS_TEXT="In Progress"; STATUS_EMOJI="ðŸŸ¡" ;;
              b) STATUS_TEXT="Blocked"; STATUS_EMOJI="ðŸŸ " ;;
              d) STATUS_TEXT="Done"; STATUS_EMOJI="âœ…" ;;
              *) STATUS_TEXT="Unknown"; STATUS_EMOJI="âšª" ;;
            esac
            
            TASK_DETAILS="${TASK_DETAILS}â€¢ ${STATUS_EMOJI} [${PRIORITY}] ${TITLE}\n"
          done
          
          # Count by priority
          P0_COUNT=$(grep -l "priority: P0" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          P1_COUNT=$(grep -l "priority: P1" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          
          # P0 tasks - separated by status (no emoji on each line)
          P0_NOT_STARTED=""
          P0_IN_PROGRESS=""
          for file in $(grep -l "priority: P0" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P0_NOT_STARTED="${P0_NOT_STARTED}â€¢ ${TITLE}\n" ;;
              s|ip|b) P0_IN_PROGRESS="${P0_IN_PROGRESS}â€¢ ${TITLE}\n" ;;
            esac
          done
          
          # P1 tasks - separated by status (no emoji on each line)
          P1_NOT_STARTED=""
          P1_IN_PROGRESS=""
          for file in $(grep -l "priority: P1" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P1_NOT_STARTED="${P1_NOT_STARTED}â€¢ ${TITLE}\n" ;;
              s|ip|b) P1_IN_PROGRESS="${P1_IN_PROGRESS}â€¢ ${TITLE}\n" ;;
            esac
          done
          
          echo "task_details<<EOF" >> $GITHUB_OUTPUT
          echo -e "$TASK_DETAILS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p0_count=$P0_COUNT" >> $GITHUB_OUTPUT
          echo "p1_count=$P1_COUNT" >> $GITHUB_OUTPUT
          
          echo "p0_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p0_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p1_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p1_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 2: AI ANALYSIS
      # ============================================
      
      - name: Generate AI Summary and Suggestions
        id: ai_analysis
        continue-on-error: true
        env:
          LLM_API_URL: ${{ secrets.LLM_API_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_MODEL_SECRET: ${{ secrets.LLM_MODEL }}
          P0_COUNT: ${{ steps.tasks.outputs.p0_count }}
          P1_COUNT: ${{ steps.tasks.outputs.p1_count }}
          JIRA_COUNT: ${{ steps.jira.outputs.jira_count }}
          JIRA_RAW: ${{ steps.jira.outputs.jira_raw }}
          CONFLUENCE_COUNT: ${{ steps.confluence.outputs.confluence_count }}
          CONFLUENCE_DATA: ${{ steps.confluence.outputs.confluence_data }}
          TASK_DETAILS: ${{ steps.tasks.outputs.task_details }}
        run: |
          MODEL="${LLM_MODEL_SECRET:-${{ env.LLM_MODEL }}}"
          
          if [ -z "$LLM_API_KEY" ]; then
            echo "full_report=_AI not configured. Add LLM_API_KEY secret._" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          read -r -d '' PROMPT << 'PROMPT_END' || true
          You are a productivity assistant. Generate a complete Slack end-of-day report.

          CRITICAL: Output must be UNDER 2800 characters total.
          Use Slack mrkdwn: *bold*, _italic_, â€¢ for bullets

          Generate this EXACT structure:

          *ðŸ“Š Daily Closing â€” [TODAY's DATE]*

          *ðŸ“ˆ Today's Activity*
          [Summarize Jira/Confluence activity in 4-6 concise bullets]
          [Group similar items, mention specific ticket keys, highlight completions]

          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          *ðŸ“‹ Task Status*
          P0: [count] | P1: [count]
          [Brief summary of what moved forward today]

          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          *ðŸ’¡ Suggested Task Updates*
          â€¢ ðŸŸ¡ *[Task name]*: _[specific update to log based on activity]_
          â€¢ âœ… *[Task name]*: _[what was completed]_
          â€¢ ðŸŸ¡ *[Task name]*: _[progress note]_

          Be CONCISE but DETAILED about actual work done today.
          PROMPT_END
          
          TODAY=$(date +'%A, %B %d, %Y')
          
          PROMPT="$PROMPT

          TODAY: $TODAY
          TASK COUNTS: P0=$P0_COUNT | P1=$P1_COUNT

          JIRA ($JIRA_COUNT issues today):
          $JIRA_RAW

          CONFLUENCE ($CONFLUENCE_COUNT pages):
          $CONFLUENCE_DATA

          TASK CONTEXT:
          $TASK_DETAILS"

          API_URL="${LLM_API_URL:-https://api.openai.com}"
          
          echo "Calling LLM to generate full report..."
          
          AI_RESPONSE=$(curl -s -X POST "${API_URL}/v1/chat/completions" \
            -H "Authorization: Bearer $LLM_API_KEY" \
            -H "Content-Type: application/json" \
            -d "$(jq -n --arg prompt "$PROMPT" --arg model "$MODEL" \
              '{
                "model": $model,
                "messages": [{"role": "user", "content": $prompt}],
                "max_tokens": 1200,
                "temperature": 0.5
              }')" 2>&1)
          
          echo "API Response: ${AI_RESPONSE:0:500}"
          
          FULL_REPORT=$(echo "$AI_RESPONSE" | jq -r '.choices[0].message.content // empty' 2>/dev/null)
          
          if [ -z "$FULL_REPORT" ]; then
            ERROR_MSG=$(echo "$AI_RESPONSE" | jq -r '.error.message // empty' 2>/dev/null)
            FULL_REPORT="*ðŸ“Š Daily Closing â€” $TODAY*\n\n_AI error: ${ERROR_MSG:-unavailable}_\n\nJira: $JIRA_COUNT issues today"
          fi
          
          # Ensure output doesn't exceed Slack limit
          if [ ${#FULL_REPORT} -gt 2900 ]; then
            FULL_REPORT="${FULL_REPORT:0:2850}...\n\n_[Truncated - open Cursor for full details]_"
          fi
          
          echo "Report length: ${#FULL_REPORT} chars"
          
          echo "full_report<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_REPORT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 3: BUILD AND SEND REPORT
      # ============================================
      
      - name: Build Slack Message
        id: report
        env:
          FULL_REPORT: ${{ steps.ai_analysis.outputs.full_report }}
        run: |
          # Use AI-generated report directly (already formatted and character-limited)
          if [ -n "$FULL_REPORT" ]; then
            echo "report<<EOF" >> $GITHUB_OUTPUT
            echo "$FULL_REPORT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            REPORT="*ðŸ“Š Daily Closing â€” $(date +'%A, %B %d, %Y')*\n\n_AI report generation failed. Check workflow logs._"
            echo "report<<EOF" >> $GITHUB_OUTPUT
            echo -e "$REPORT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

      - name: Send to Slack
        uses: slackapi/slack-github-action@v1.27.0
        with:
          channel-id: ${{ secrets.SLACK_CHANNEL_ID }}
          payload: |
            {
              "text": "Daily Closing",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": ${{ toJSON(steps.report.outputs.report) }}
                  }
                }
              ]
            }
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
