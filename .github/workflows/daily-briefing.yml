# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Daily Briefing

# AI-powered morning briefing with task focus recommendations
# Requires secrets: ATLASSIAN_*, LLM_*, SLACK_*

on:
  schedule:
    # 8:30 AM BRT (11:30 UTC) Mon-Fri
    - cron: '30 11 * * 1-5'
  workflow_dispatch:

env:
  # LLM Model (can be overridden via secret LLM_MODEL)
  LLM_MODEL: "gpt-4o-mini"

jobs:
  daily-briefing:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # ============================================
      # STEP 1: GATHER DATA
      # ============================================
      
      - name: Fetch Jira Activity
        id: jira
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          JIRA_PROJECT: ${{ secrets.JIRA_PROJECT }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$JIRA_PROJECT" ]; then
            echo "jira_data=_Jira not configured_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching Jira activity from $ATLASSIAN_DOMAIN..."
          
          # Use new Jira API endpoint (POST /rest/api/3/search/jql)
          # Old /rest/api/3/search was deprecated and removed (HTTP 410)
          JQL="project = ${JIRA_PROJECT} AND updated >= -24h ORDER BY updated DESC"
          
          echo "JQL: $JQL"
          
          # Create JSON payload for POST request
          JSON_PAYLOAD=$(jq -n \
            --arg jql "$JQL" \
            '{
              "jql": $jql,
              "maxResults": 20,
              "fields": ["key", "summary", "status", "assignee", "updated"]
            }')
          
          echo "Payload: $JSON_PAYLOAD"
          
          JIRA_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
            -X POST \
            -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://${ATLASSIAN_DOMAIN}/rest/api/3/search/jql" \
            -d "$JSON_PAYLOAD")
          
          # Extract HTTP code and response body
          HTTP_CODE=$(echo "$JIRA_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
          RESPONSE_BODY=$(echo "$JIRA_RESPONSE" | grep -v "HTTP_CODE:")
          
          echo "HTTP Code: $HTTP_CODE"
          echo "Response: ${RESPONSE_BODY:0:500}"
          
          if [ "$HTTP_CODE" != "200" ]; then
            echo "Jira API error: HTTP $HTTP_CODE"
            echo "jira_data=_Jira API error_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          JIRA_COUNT=$(echo "$RESPONSE_BODY" | jq -r '.issues | length' 2>/dev/null || echo "0")
          
          # Get full issue list for AI to summarize (key, summary, status)
          JIRA_RAW=$(echo "$RESPONSE_BODY" | jq -r '.issues[]? | "\(.key): \(.fields.summary) [\(.fields.status.name)]"' 2>/dev/null || echo "")
          
          echo "Found $JIRA_COUNT issues"
          
          if [ -z "$JIRA_RAW" ] || [ "$JIRA_COUNT" = "0" ]; then
            JIRA_RAW="_No Jira activity in the last 24h_"
          fi
          
          # Output raw data for AI to summarize
          echo "jira_raw<<EOF" >> $GITHUB_OUTPUT
          echo "$JIRA_RAW" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "jira_count=$JIRA_COUNT" >> $GITHUB_OUTPUT

      - name: Fetch Confluence Activity
        id: confluence
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          CONFLUENCE_SPACES: ${{ secrets.CONFLUENCE_SPACES }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$CONFLUENCE_SPACES" ]; then
            echo "confluence_data=_Confluence not configured_" >> $GITHUB_OUTPUT
            echo "confluence_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching Confluence activity..."
          
          # Get recently modified pages across spaces
          ALL_PAGES=""
          TOTAL_COUNT=0
          
          for SPACE in $(echo $CONFLUENCE_SPACES | tr ',' ' '); do
            RESPONSE=$(curl -s -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
              "https://${ATLASSIAN_DOMAIN}/wiki/rest/api/content?spaceKey=${SPACE}&expand=history.lastUpdated&limit=10&orderby=history.lastUpdated%20desc" \
              2>/dev/null || echo '{"results":[]}')
            
            # Get pages modified in last 24h
            YESTERDAY=$(date -u -d '24 hours ago' +%Y-%m-%dT%H:%M:%S 2>/dev/null || date -u -v-24H +%Y-%m-%dT%H:%M:%S)
            PAGES=$(echo "$RESPONSE" | jq -r --arg yesterday "$YESTERDAY" \
              '.results[]? | select(.history.lastUpdated.when > $yesterday) | "‚Ä¢ \(.title)"' 2>/dev/null || echo "")
            
            if [ -n "$PAGES" ]; then
              ALL_PAGES="${ALL_PAGES}${PAGES}\n"
              COUNT=$(echo "$PAGES" | grep -c "‚Ä¢" || echo "0")
              TOTAL_COUNT=$((TOTAL_COUNT + COUNT))
            fi
          done
          
          if [ -z "$ALL_PAGES" ] || [ "$TOTAL_COUNT" = "0" ]; then
            ALL_PAGES="_No Confluence edits in the last 24h_"
          fi
          
          echo "confluence_data<<EOF" >> $GITHUB_OUTPUT
          echo -e "$ALL_PAGES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "confluence_count=$TOTAL_COUNT" >> $GITHUB_OUTPUT

      # Note: Slack message fetching requires user token (restricted in many companies)
      # For full Slack access, use the local script: scripts/logbook-local.py
      # It can leverage Slack MCP OAuth tokens for unrestricted access

      - name: Read Current Tasks
        id: tasks
        run: |
          # Count by priority
          P0_COUNT=$(grep -l "priority: P0" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          P1_COUNT=$(grep -l "priority: P1" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          BLOCKED_COUNT=$(grep -l "status: b" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          
          # Get P0 tasks - separated by status (no emoji on each line)
          P0_NOT_STARTED=""
          P0_IN_PROGRESS=""
          for file in $(grep -l "priority: P0" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P0_NOT_STARTED="${P0_NOT_STARTED}‚Ä¢ ${TITLE}\n" ;;
              s|ip|b) P0_IN_PROGRESS="${P0_IN_PROGRESS}‚Ä¢ ${TITLE}\n" ;;
            esac
          done
          
          # Get P1 tasks - separated by status (no emoji on each line)
          P1_NOT_STARTED=""
          P1_IN_PROGRESS=""
          for file in $(grep -l "priority: P1" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P1_NOT_STARTED="${P1_NOT_STARTED}‚Ä¢ ${TITLE}\n" ;;
              s|ip|b) P1_IN_PROGRESS="${P1_IN_PROGRESS}‚Ä¢ ${TITLE}\n" ;;
            esac
          done
          
          # Get blocked tasks (across all priorities)
          BLOCKED_TASKS=""
          for file in $(grep -l "status: b" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            BLOCKED_TASKS="${BLOCKED_TASKS}‚Ä¢ ${TITLE}\n"
          done
          
          # Extract detailed context from top priority tasks for AI analysis
          # Get P0 not-started tasks with full context (most important for AI)
          TASK_DETAILS=""
          for file in $(grep -l "priority: P0" Tasks/*.md 2>/dev/null | head -3 || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            # Extract Context section (first 3 lines after ## Context)
            CONTEXT=$(sed -n '/^## Context/,/^##/{/^## Context/d;/^##/d;p}' "$file" | head -3 | tr '\n' ' ')
            # Extract latest Progress Log entry
            PROGRESS=$(sed -n '/^## Progress Log/,/^##/{/^## Progress Log/d;/^##/d;p}' "$file" | grep "^-" | tail -1)
            
            case $STATUS in
              n) STATUS_EMOJI="üî¥" ;;
              s|ip) STATUS_EMOJI="üü°" ;;
              b) STATUS_EMOJI="üü†" ;;
              *) STATUS_EMOJI="‚ö™" ;;
            esac
            
            TASK_DETAILS="${TASK_DETAILS}---\nTASK: ${TITLE}\nSTATUS: ${STATUS_EMOJI}\nCONTEXT: ${CONTEXT}\nLATEST: ${PROGRESS}\n"
          done
          
          # Also get top P1 not-started tasks
          for file in $(grep -l "priority: P1" Tasks/*.md 2>/dev/null | head -3 || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            CONTEXT=$(sed -n '/^## Context/,/^##/{/^## Context/d;/^##/d;p}' "$file" | head -3 | tr '\n' ' ')
            PROGRESS=$(sed -n '/^## Progress Log/,/^##/{/^## Progress Log/d;/^##/d;p}' "$file" | grep "^-" | tail -1)
            
            case $STATUS in
              n) STATUS_EMOJI="üî¥" ;;
              s|ip) STATUS_EMOJI="üü°" ;;
              b) STATUS_EMOJI="üü†" ;;
              *) STATUS_EMOJI="‚ö™" ;;
            esac
            
            TASK_DETAILS="${TASK_DETAILS}---\nTASK: ${TITLE}\nSTATUS: ${STATUS_EMOJI}\nCONTEXT: ${CONTEXT}\nLATEST: ${PROGRESS}\n"
          done
          
          # Output counts
          echo "p0_count=$P0_COUNT" >> $GITHUB_OUTPUT
          echo "p1_count=$P1_COUNT" >> $GITHUB_OUTPUT
          echo "blocked_count=$BLOCKED_COUNT" >> $GITHUB_OUTPUT
          
          # Output P0 tasks - separate not started and in progress
          echo "p0_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p0_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Output P1 tasks - separate not started and in progress
          echo "p1_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p1_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "blocked_tasks<<EOF" >> $GITHUB_OUTPUT
          echo -e "$BLOCKED_TASKS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Output detailed task context for AI
          echo "task_details<<EOF" >> $GITHUB_OUTPUT
          echo -e "$TASK_DETAILS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 2: AI ANALYSIS
      # ============================================
      
      - name: Generate AI Summary and Recommendations
        id: ai_analysis
        continue-on-error: true
        env:
          LLM_API_URL: ${{ secrets.LLM_API_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_MODEL_SECRET: ${{ secrets.LLM_MODEL }}
          P0_COUNT: ${{ steps.tasks.outputs.p0_count }}
          P1_COUNT: ${{ steps.tasks.outputs.p1_count }}
          P0_NOT_STARTED: ${{ steps.tasks.outputs.p0_not_started }}
          P0_IN_PROGRESS: ${{ steps.tasks.outputs.p0_in_progress }}
          P1_NOT_STARTED: ${{ steps.tasks.outputs.p1_not_started }}
          P1_IN_PROGRESS: ${{ steps.tasks.outputs.p1_in_progress }}
          BLOCKED_COUNT: ${{ steps.tasks.outputs.blocked_count }}
          TASK_DETAILS: ${{ steps.tasks.outputs.task_details }}
          JIRA_RAW: ${{ steps.jira.outputs.jira_raw }}
          JIRA_COUNT: ${{ steps.jira.outputs.jira_count }}
          CONFLUENCE_DATA: ${{ steps.confluence.outputs.confluence_data }}
          CONFLUENCE_COUNT: ${{ steps.confluence.outputs.confluence_count }}
        run: |
          MODEL="${LLM_MODEL_SECRET:-${{ env.LLM_MODEL }}}"
          
          if [ -z "$LLM_API_KEY" ]; then
            echo "full_report=_AI not configured. Add LLM_API_KEY secret._" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Build comprehensive prompt for AI to generate the ENTIRE Slack message
          read -r -d '' PROMPT << 'PROMPT_END' || true
          You are a productivity assistant. Generate a complete Slack daily briefing.

          CRITICAL: Output must be UNDER 2800 characters total.
          Use Slack mrkdwn: *bold*, _italic_, ‚Ä¢ for bullets

          Generate this EXACT structure (follow formatting precisely):

          *‚òÄÔ∏è Daily Briefing ‚Äî [TODAY's DATE]*

          *üö® P0 Tasks (Do Today):* [count]
          *üî¥ Not started*
          ‚Ä¢ [task name - truncate if over 50 chars]
          ‚Ä¢ [task name]
          *üü° In Progress*
          ‚Ä¢ [task name]

          *‚ö° P1 Tasks (This Week):* [count]
          *üî¥ Not started*
          ‚Ä¢ [task name]
          *üü° In Progress*
          ‚Ä¢ [task name]
          ‚Ä¢ [task name]

          ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

          *üìä Recent Activity (24h)*
          [Intelligently summarize Jira activity in 3-5 bullets - group similar items, mention specific ticket keys]
          [Mention Confluence if any activity]

          ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

          *üí° AI Focus Recommendation*
          ‚Ä¢ üî¥ *[Task name]*: _[1-line reason why this matters]_
          ‚Ä¢ üü° *[Task name]*: _[1-line reason]_
          ‚Ä¢ üü° *[Task name]*: _[1-line reason]_

          IMPORTANT TASK FORMAT RULES:
          - Group tasks by status with HEADER then list (NOT emoji per line)
          - Status headers: *üî¥ Not started* and *üü° In Progress* (as bold headers)
          - Task bullets have NO emoji, just ‚Ä¢ [task name]
          - Only show status headers that have tasks
          - Skip empty groups entirely
          PROMPT_END
          
          TODAY=$(date +'%A, %B %d, %Y')
          
          PROMPT="$PROMPT

          TODAY: $TODAY

          RAW DATA TO SUMMARIZE:

          P0 TASKS ($P0_COUNT total):
          Not started: $P0_NOT_STARTED
          In progress: $P0_IN_PROGRESS

          P1 TASKS ($P1_COUNT total):
          Not started: $P1_NOT_STARTED
          In progress: $P1_IN_PROGRESS

          BLOCKED: $BLOCKED_COUNT

          JIRA ($JIRA_COUNT issues in last 24h):
          $JIRA_RAW

          CONFLUENCE ($CONFLUENCE_COUNT pages):
          $CONFLUENCE_DATA

          TASK CONTEXT FOR RECOMMENDATIONS:
          $TASK_DETAILS"

          API_URL="${LLM_API_URL:-https://api.openai.com}"
          
          echo "Calling LLM to generate full report..."
          
          AI_RESPONSE=$(curl -s -X POST "${API_URL}/v1/chat/completions" \
            -H "Authorization: Bearer $LLM_API_KEY" \
            -H "Content-Type: application/json" \
            -d "$(jq -n --arg prompt "$PROMPT" --arg model "$MODEL" \
              '{
                "model": $model,
                "messages": [{"role": "user", "content": $prompt}],
                "max_tokens": 1200,
                "temperature": 0.5
              }')" 2>&1)
          
          echo "API Response: ${AI_RESPONSE:0:500}"
          
          FULL_REPORT=$(echo "$AI_RESPONSE" | jq -r '.choices[0].message.content // empty' 2>/dev/null)
          
          if [ -z "$FULL_REPORT" ]; then
            ERROR_MSG=$(echo "$AI_RESPONSE" | jq -r '.error.message // empty' 2>/dev/null)
            FULL_REPORT="*‚òÄÔ∏è Daily Briefing ‚Äî $TODAY*\n\n_AI error: ${ERROR_MSG:-unavailable}_\n\nP0: $P0_COUNT | P1: $P1_COUNT | Jira: $JIRA_COUNT issues"
          fi
          
          # Ensure output doesn't exceed Slack limit (truncate if needed)
          if [ ${#FULL_REPORT} -gt 2900 ]; then
            FULL_REPORT="${FULL_REPORT:0:2850}...\n\n_[Truncated - open Cursor for full details]_"
          fi
          
          echo "Report length: ${#FULL_REPORT} chars"
          
          echo "full_report<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_REPORT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 3: BUILD AND SEND REPORT
      # ============================================
      
      - name: Build Slack Message
        id: report
        env:
          FULL_REPORT: ${{ steps.ai_analysis.outputs.full_report }}
        run: |
          # Use AI-generated report directly (already formatted and character-limited)
          if [ -n "$FULL_REPORT" ]; then
            echo "report<<EOF" >> $GITHUB_OUTPUT
            echo "$FULL_REPORT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            # Fallback if AI failed
            REPORT="*‚òÄÔ∏è Daily Briefing ‚Äî $(date +'%A, %B %d, %Y')*\n\n_AI report generation failed. Check workflow logs._"
            echo "report<<EOF" >> $GITHUB_OUTPUT
            echo -e "$REPORT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

      - name: Send to Slack
        uses: slackapi/slack-github-action@v1.27.0
        with:
          channel-id: ${{ secrets.SLACK_CHANNEL_ID }}
          payload: |
            {
              "text": "Daily Briefing",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": ${{ toJSON(steps.report.outputs.report) }}
                  }
                }
              ]
            }
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
