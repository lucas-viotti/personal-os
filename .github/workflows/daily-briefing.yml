# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Daily Briefing

# AI-powered morning briefing with task focus recommendations
# Requires secrets: ATLASSIAN_*, LLM_*, SLACK_*

on:
  schedule:
    # 8:30 AM BRT (11:30 UTC) Mon-Fri
    - cron: '30 11 * * 1-5'
  workflow_dispatch:

env:
  # LLM Model (can be overridden via secret LLM_MODEL)
  LLM_MODEL: "gpt-4o-mini"

jobs:
  daily-briefing:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # ============================================
      # STEP 1: GATHER DATA
      # ============================================
      
      - name: Fetch Jira Activity
        id: jira
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          JIRA_PROJECT: ${{ secrets.JIRA_PROJECT }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$JIRA_PROJECT" ]; then
            echo "jira_data=_Jira not configured_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching Jira activity from $ATLASSIAN_DOMAIN..."
          
          # Use new Jira API endpoint (POST /rest/api/3/search/jql)
          # Old /rest/api/3/search was deprecated and removed (HTTP 410)
          JQL="project = ${JIRA_PROJECT} AND updated >= -24h ORDER BY updated DESC"
          
          echo "JQL: $JQL"
          
          # Create JSON payload for POST request
          JSON_PAYLOAD=$(jq -n \
            --arg jql "$JQL" \
            '{
              "jql": $jql,
              "maxResults": 20,
              "fields": ["key", "summary", "status", "assignee", "updated"]
            }')
          
          echo "Payload: $JSON_PAYLOAD"
          
          JIRA_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
            -X POST \
            -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://${ATLASSIAN_DOMAIN}/rest/api/3/search/jql" \
            -d "$JSON_PAYLOAD")
          
          # Extract HTTP code and response body
          HTTP_CODE=$(echo "$JIRA_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
          RESPONSE_BODY=$(echo "$JIRA_RESPONSE" | grep -v "HTTP_CODE:")
          
          echo "HTTP Code: $HTTP_CODE"
          echo "Response: ${RESPONSE_BODY:0:500}"
          
          if [ "$HTTP_CODE" != "200" ]; then
            echo "Jira API error: HTTP $HTTP_CODE"
            echo "jira_data=_Jira API error_" >> $GITHUB_OUTPUT
            echo "jira_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          JIRA_COUNT=$(echo "$RESPONSE_BODY" | jq -r '.issues | length' 2>/dev/null || echo "0")
          JIRA_ISSUES=$(echo "$RESPONSE_BODY" | jq -r '.issues[]? | "‚Ä¢ \(.key): \(.fields.summary) [\(.fields.status.name)]"' 2>/dev/null || echo "")
          
          echo "Found $JIRA_COUNT issues"
          
          if [ -z "$JIRA_ISSUES" ] || [ "$JIRA_COUNT" = "0" ]; then
            JIRA_ISSUES="_No Jira activity in the last 24h_"
          fi
          
          echo "jira_data<<EOF" >> $GITHUB_OUTPUT
          echo "$JIRA_ISSUES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "jira_count=$JIRA_COUNT" >> $GITHUB_OUTPUT

      - name: Fetch Confluence Activity
        id: confluence
        continue-on-error: true
        env:
          ATLASSIAN_DOMAIN: ${{ secrets.ATLASSIAN_DOMAIN }}
          ATLASSIAN_EMAIL: ${{ secrets.ATLASSIAN_EMAIL }}
          ATLASSIAN_API_TOKEN: ${{ secrets.ATLASSIAN_API_TOKEN }}
          CONFLUENCE_SPACES: ${{ secrets.CONFLUENCE_SPACES }}
        run: |
          if [ -z "$ATLASSIAN_DOMAIN" ] || [ -z "$CONFLUENCE_SPACES" ]; then
            echo "confluence_data=_Confluence not configured_" >> $GITHUB_OUTPUT
            echo "confluence_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Fetching Confluence activity..."
          
          # Get recently modified pages across spaces
          ALL_PAGES=""
          TOTAL_COUNT=0
          
          for SPACE in $(echo $CONFLUENCE_SPACES | tr ',' ' '); do
            RESPONSE=$(curl -s -u "${ATLASSIAN_EMAIL}:${ATLASSIAN_API_TOKEN}" \
              "https://${ATLASSIAN_DOMAIN}/wiki/rest/api/content?spaceKey=${SPACE}&expand=history.lastUpdated&limit=10&orderby=history.lastUpdated%20desc" \
              2>/dev/null || echo '{"results":[]}')
            
            # Get pages modified in last 24h
            YESTERDAY=$(date -u -d '24 hours ago' +%Y-%m-%dT%H:%M:%S 2>/dev/null || date -u -v-24H +%Y-%m-%dT%H:%M:%S)
            PAGES=$(echo "$RESPONSE" | jq -r --arg yesterday "$YESTERDAY" \
              '.results[]? | select(.history.lastUpdated.when > $yesterday) | "‚Ä¢ \(.title)"' 2>/dev/null || echo "")
            
            if [ -n "$PAGES" ]; then
              ALL_PAGES="${ALL_PAGES}${PAGES}\n"
              COUNT=$(echo "$PAGES" | grep -c "‚Ä¢" || echo "0")
              TOTAL_COUNT=$((TOTAL_COUNT + COUNT))
            fi
          done
          
          if [ -z "$ALL_PAGES" ] || [ "$TOTAL_COUNT" = "0" ]; then
            ALL_PAGES="_No Confluence edits in the last 24h_"
          fi
          
          echo "confluence_data<<EOF" >> $GITHUB_OUTPUT
          echo -e "$ALL_PAGES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "confluence_count=$TOTAL_COUNT" >> $GITHUB_OUTPUT

      # Note: Slack message fetching requires user token (restricted in many companies)
      # For full Slack access, use the local script: scripts/logbook-local.py
      # It can leverage Slack MCP OAuth tokens for unrestricted access

      - name: Read Current Tasks
        id: tasks
        run: |
          # Count by priority
          P0_COUNT=$(grep -l "priority: P0" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          P1_COUNT=$(grep -l "priority: P1" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          BLOCKED_COUNT=$(grep -l "status: b" Tasks/*.md 2>/dev/null | wc -l | tr -d ' ')
          
          # Get P0 tasks - separated by status (no emoji on each line)
          P0_NOT_STARTED=""
          P0_IN_PROGRESS=""
          for file in $(grep -l "priority: P0" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P0_NOT_STARTED="${P0_NOT_STARTED}‚Ä¢ ${TITLE}\n" ;;
              s|ip|b) P0_IN_PROGRESS="${P0_IN_PROGRESS}‚Ä¢ ${TITLE}\n" ;;
            esac
          done
          
          # Get P1 tasks - separated by status (no emoji on each line)
          P1_NOT_STARTED=""
          P1_IN_PROGRESS=""
          for file in $(grep -l "priority: P1" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            case $STATUS in
              n) P1_NOT_STARTED="${P1_NOT_STARTED}‚Ä¢ ${TITLE}\n" ;;
              s|ip|b) P1_IN_PROGRESS="${P1_IN_PROGRESS}‚Ä¢ ${TITLE}\n" ;;
            esac
          done
          
          # Get blocked tasks (across all priorities)
          BLOCKED_TASKS=""
          for file in $(grep -l "status: b" Tasks/*.md 2>/dev/null || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            BLOCKED_TASKS="${BLOCKED_TASKS}‚Ä¢ ${TITLE}\n"
          done
          
          # Extract detailed context from top priority tasks for AI analysis
          # Get P0 not-started tasks with full context (most important for AI)
          TASK_DETAILS=""
          for file in $(grep -l "priority: P0" Tasks/*.md 2>/dev/null | head -3 || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            # Extract Context section (first 3 lines after ## Context)
            CONTEXT=$(sed -n '/^## Context/,/^##/{/^## Context/d;/^##/d;p}' "$file" | head -3 | tr '\n' ' ')
            # Extract latest Progress Log entry
            PROGRESS=$(sed -n '/^## Progress Log/,/^##/{/^## Progress Log/d;/^##/d;p}' "$file" | grep "^-" | tail -1)
            
            case $STATUS in
              n) STATUS_EMOJI="üî¥" ;;
              s|ip) STATUS_EMOJI="üü°" ;;
              b) STATUS_EMOJI="üü†" ;;
              *) STATUS_EMOJI="‚ö™" ;;
            esac
            
            TASK_DETAILS="${TASK_DETAILS}---\nTASK: ${TITLE}\nSTATUS: ${STATUS_EMOJI}\nCONTEXT: ${CONTEXT}\nLATEST: ${PROGRESS}\n"
          done
          
          # Also get top P1 not-started tasks
          for file in $(grep -l "priority: P1" Tasks/*.md 2>/dev/null | head -3 || echo ""); do
            TITLE=$(grep "^title:" "$file" | sed 's/title: //' | head -1)
            STATUS=$(grep "^status:" "$file" | sed 's/status: //' | head -1)
            CONTEXT=$(sed -n '/^## Context/,/^##/{/^## Context/d;/^##/d;p}' "$file" | head -3 | tr '\n' ' ')
            PROGRESS=$(sed -n '/^## Progress Log/,/^##/{/^## Progress Log/d;/^##/d;p}' "$file" | grep "^-" | tail -1)
            
            case $STATUS in
              n) STATUS_EMOJI="üî¥" ;;
              s|ip) STATUS_EMOJI="üü°" ;;
              b) STATUS_EMOJI="üü†" ;;
              *) STATUS_EMOJI="‚ö™" ;;
            esac
            
            TASK_DETAILS="${TASK_DETAILS}---\nTASK: ${TITLE}\nSTATUS: ${STATUS_EMOJI}\nCONTEXT: ${CONTEXT}\nLATEST: ${PROGRESS}\n"
          done
          
          # Output counts
          echo "p0_count=$P0_COUNT" >> $GITHUB_OUTPUT
          echo "p1_count=$P1_COUNT" >> $GITHUB_OUTPUT
          echo "blocked_count=$BLOCKED_COUNT" >> $GITHUB_OUTPUT
          
          # Output P0 tasks - separate not started and in progress
          echo "p0_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p0_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P0_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Output P1 tasks - separate not started and in progress
          echo "p1_not_started<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_NOT_STARTED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "p1_in_progress<<EOF" >> $GITHUB_OUTPUT
          echo -e "$P1_IN_PROGRESS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "blocked_tasks<<EOF" >> $GITHUB_OUTPUT
          echo -e "$BLOCKED_TASKS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Output detailed task context for AI
          echo "task_details<<EOF" >> $GITHUB_OUTPUT
          echo -e "$TASK_DETAILS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 2: AI ANALYSIS
      # ============================================
      
      - name: Generate AI Focus Suggestions
        id: ai_analysis
        continue-on-error: true
        env:
          LLM_API_URL: ${{ secrets.LLM_API_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_MODEL_SECRET: ${{ secrets.LLM_MODEL }}
          P0_COUNT: ${{ steps.tasks.outputs.p0_count }}
          P1_COUNT: ${{ steps.tasks.outputs.p1_count }}
          BLOCKED_COUNT: ${{ steps.tasks.outputs.blocked_count }}
          TASK_DETAILS: ${{ steps.tasks.outputs.task_details }}
          JIRA_DATA: ${{ steps.jira.outputs.jira_data }}
          CONFLUENCE_DATA: ${{ steps.confluence.outputs.confluence_data }}
        run: |
          # Use secret model if set, otherwise use env default
          MODEL="${LLM_MODEL_SECRET:-${{ env.LLM_MODEL }}}"
          
          if [ -z "$LLM_API_KEY" ]; then
            echo "suggestions=_AI analysis not configured. Add LLM_API_KEY secret._" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Build the prompt using heredoc to avoid YAML parsing issues
          read -r -d '' PROMPT << 'PROMPT_END' || true
          You are a productivity assistant helping a Product Manager prioritize their day.
          
          IMPORTANT RULES:
          - Select ONLY 2-3 tasks to focus on today (no more!)
          - For each task, explain WHY it should be prioritized based on its context
          - Use Slack mrkdwn: bold with *, italics with _
          - Use status emoji: üî¥ (not started), üü° (in progress), üü† (blocked)
          
          OUTPUT FORMAT (exactly this, no subtitles or headers):
          ‚Ä¢ [emoji] *Task name*
          _[1 sentence reason why this task matters today based on context]_
          
          ‚Ä¢ [emoji] *Another task*
          _[1 sentence reason based on context]_
          
          DO NOT include:
          - "Focus Recommendation:" or "Tasks Needing Attention:" headers
          - More than 3 tasks
          - Generic advice - be specific to the task context provided
          PROMPT_END
          
          # Append dynamic context
          PROMPT="$PROMPT

          TODAY: $(date +'%A, %B %d, %Y')
          SUMMARY: P0=$P0_COUNT | P1=$P1_COUNT | Blocked=$BLOCKED_COUNT
          
          TASK DETAILS WITH CONTEXT:
          $TASK_DETAILS
          
          RECENT ACTIVITY:
          Jira: $JIRA_DATA
          Confluence: $CONFLUENCE_DATA"

          # Determine API URL
          API_URL="${LLM_API_URL:-https://api.openai.com}"
          
          echo "Calling LLM API at $API_URL..."
          
          # Make the API call
          AI_RESPONSE=$(curl -s -X POST "${API_URL}/v1/chat/completions" \
            -H "Authorization: Bearer $LLM_API_KEY" \
            -H "Content-Type: application/json" \
            -d "$(jq -n --arg prompt "$PROMPT" --arg model "$MODEL" \
              '{
                "model": $model,
                "messages": [{"role": "user", "content": $prompt}],
                "max_tokens": 500,
                "temperature": 0.7
              }')" 2>&1)
          
          echo "API Response: $AI_RESPONSE"
          
          # Extract the response
          AI_SUGGESTIONS=$(echo "$AI_RESPONSE" | jq -r '.choices[0].message.content // empty' 2>/dev/null)
          
          if [ -z "$AI_SUGGESTIONS" ]; then
            # Check for error message
            ERROR_MSG=$(echo "$AI_RESPONSE" | jq -r '.error.message // empty' 2>/dev/null)
            if [ -n "$ERROR_MSG" ]; then
              AI_SUGGESTIONS="_AI error: ${ERROR_MSG}_"
            else
              AI_SUGGESTIONS="_AI analysis unavailable_"
            fi
          fi
          
          echo "suggestions<<EOF" >> $GITHUB_OUTPUT
          echo "$AI_SUGGESTIONS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # ============================================
      # STEP 3: BUILD AND SEND REPORT
      # ============================================
      
      - name: Build Slack Message
        id: report
        env:
          P0_COUNT: ${{ steps.tasks.outputs.p0_count }}
          P1_COUNT: ${{ steps.tasks.outputs.p1_count }}
          BLOCKED_COUNT: ${{ steps.tasks.outputs.blocked_count }}
          P0_NOT_STARTED: ${{ steps.tasks.outputs.p0_not_started }}
          P0_IN_PROGRESS: ${{ steps.tasks.outputs.p0_in_progress }}
          P1_NOT_STARTED: ${{ steps.tasks.outputs.p1_not_started }}
          P1_IN_PROGRESS: ${{ steps.tasks.outputs.p1_in_progress }}
          BLOCKED_TASKS: ${{ steps.tasks.outputs.blocked_tasks }}
          JIRA_COUNT: ${{ steps.jira.outputs.jira_count }}
          JIRA_DATA: ${{ steps.jira.outputs.jira_data }}
          CONFLUENCE_COUNT: ${{ steps.confluence.outputs.confluence_count }}
          CONFLUENCE_DATA: ${{ steps.confluence.outputs.confluence_data }}
          AI_SUGGESTIONS: ${{ steps.ai_analysis.outputs.suggestions }}
        run: |
          REPORT="*‚òÄÔ∏è Daily Briefing ‚Äî $(date +'%A, %B %d, %Y')*\n\n"
          
          # P0 Tasks - grouped by status
          REPORT+="*üö® P0 Tasks (Do Today):* ${P0_COUNT:-0}\n"
          if [ -n "$P0_NOT_STARTED" ] && [ "$P0_NOT_STARTED" != "\n" ]; then
            REPORT+="*üî¥ Not started*\n"
            REPORT+="${P0_NOT_STARTED}"
          fi
          if [ -n "$P0_IN_PROGRESS" ] && [ "$P0_IN_PROGRESS" != "\n" ]; then
            REPORT+="*üü° In Progress*\n"
            REPORT+="${P0_IN_PROGRESS}"
          fi
          if [ "${P0_COUNT:-0}" -eq 0 ]; then
            REPORT+="_None_\n"
          fi
          REPORT+="\n"
          
          # P1 Tasks - grouped by status
          REPORT+="*‚ö° P1 Tasks (This Week):* ${P1_COUNT:-0}\n"
          if [ -n "$P1_NOT_STARTED" ] && [ "$P1_NOT_STARTED" != "\n" ]; then
            REPORT+="*üî¥ Not started*\n"
            REPORT+="${P1_NOT_STARTED}"
          fi
          if [ -n "$P1_IN_PROGRESS" ] && [ "$P1_IN_PROGRESS" != "\n" ]; then
            REPORT+="*üü° In Progress*\n"
            REPORT+="${P1_IN_PROGRESS}"
          fi
          if [ "${P1_COUNT:-0}" -eq 0 ]; then
            REPORT+="_None_\n"
          fi
          REPORT+="\n"
          
          # Blocked warning
          if [ "${BLOCKED_COUNT:-0}" -gt 0 ]; then
            REPORT+="*‚ö†Ô∏è Blocked Tasks:* ${BLOCKED_COUNT}\n"
            REPORT+="${BLOCKED_TASKS}\n"
          fi
          
          REPORT+="‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
          
          # Recent Activity - show details if available
          REPORT+="*üìä Recent Activity (24h)*\n"
          if [ "${JIRA_COUNT:-0}" -gt 0 ]; then
            REPORT+="*üìã Jira (${JIRA_COUNT}):*\n${JIRA_DATA}\n\n"
          else
            REPORT+="‚Ä¢ üìã Jira: _No activity_\n"
          fi
          
          if [ "${CONFLUENCE_COUNT:-0}" -gt 0 ]; then
            REPORT+="*üìù Confluence (${CONFLUENCE_COUNT}):*\n${CONFLUENCE_DATA}\n\n"
          else
            REPORT+="‚Ä¢ üìù Confluence: _No activity_\n"
          fi
          REPORT+="‚Ä¢ üí¨ Slack: _Ask Cursor IDE for context_\n\n"
          
          REPORT+="‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
          
          # AI Suggestions
          REPORT+="*üí° AI Focus Recommendation*\n"
          REPORT+="${AI_SUGGESTIONS:-_AI analysis not available_}\n\n"
          
          REPORT+="‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
          REPORT+="_Open Cursor IDE to analyze Slack activity or apply task updates_"
          
          echo "report<<EOF" >> $GITHUB_OUTPUT
          echo -e "$REPORT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Send to Slack
        uses: slackapi/slack-github-action@v1.27.0
        with:
          channel-id: ${{ secrets.SLACK_CHANNEL_ID }}
          payload: |
            {
              "text": "Daily Briefing",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": ${{ toJSON(steps.report.outputs.report) }}
                  }
                }
              ]
            }
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
